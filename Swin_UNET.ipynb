{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKXs9swTz_OC"
      },
      "source": [
        "# Image segmentation with SwinUNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQbWqsTe074c",
        "outputId": "740fd1fd-0974-4107-b9f6-ee50bc62f65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'keras-vision-transformer'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 95 (delta 45), reused 35 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (95/95), 155.59 KiB | 1.60 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yingkaisha/keras-vision-transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHGMAD0Uz_OT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG6AR6Lvz_Oa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUZ4oJqEz_Od"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "\n",
        "from keras_vision_transformer import swin_layers\n",
        "from keras_vision_transformer import transformer_layers\n",
        "from keras_vision_transformer import utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBth39u4z_Of"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKKhqbmpQYDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc6c546-d7b3-45ae-d06c-30443c5794c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file = zipfile.ZipFile('/content/gdrive/MyDrive/Glaucoma_lengkap.zip', 'r')\n",
        "zip_file.extractall('/content/')"
      ],
      "metadata": {
        "id": "vgr-VMGKmnTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7dSq3rTz_Ok"
      },
      "outputs": [],
      "source": [
        "# the indicator of a fresh run\n",
        "first_time_running = False\n",
        "\n",
        "# user-specified working directory\n",
        "# filepath = '/content/oxford_iiit'\n",
        "filepath = '/tmp/TrainData'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-o1s0Sez_Ot"
      },
      "source": [
        "# The Swin-UNET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOWfkFTNz_Ow"
      },
      "source": [
        "Two functions are provided for customizing the Swin-UNET:\n",
        "    \n",
        "* `swin_transformer_stack`: a function that stacks multiple Swin Transformers.\n",
        "* `swin_unet_2d_base`: the base architecture of the Swin-UNET with down-/upsampling levels and skip connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VxtfPIkz_Oy"
      },
      "outputs": [],
      "source": [
        "def swin_transformer_stack(X, stack_num, embed_dim, num_patch, num_heads, window_size, num_mlp, shift_window=True, name=''):\n",
        "    '''\n",
        "    Stacked Swin Transformers that share the same token size.\n",
        "\n",
        "    Alternated Window-MSA and Swin-MSA will be configured if `shift_window=True`, Window-MSA only otherwise.\n",
        "    *Dropout is turned off.\n",
        "    '''\n",
        "    # Turn-off dropouts\n",
        "    mlp_drop_rate = 0 # Droupout after each MLP layer\n",
        "    attn_drop_rate = 0 # Dropout after Swin-Attention\n",
        "    proj_drop_rate = 0 # Dropout at the end of each Swin-Attention block, i.e., after linear projections\n",
        "    drop_path_rate = 0 # Drop-path within skip-connections\n",
        "\n",
        "    qkv_bias = True # Convert embedded patches to query, key, and values with a learnable additive value\n",
        "    qk_scale = None # None: Re-scale query based on embed dimensions per attention head # Float for user specified scaling factor\n",
        "\n",
        "    if shift_window:\n",
        "        shift_size = window_size // 2\n",
        "    else:\n",
        "        shift_size = 0\n",
        "\n",
        "    for i in range(stack_num):\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            shift_size_temp = 0\n",
        "        else:\n",
        "            shift_size_temp = shift_size\n",
        "\n",
        "        X = swin_layers.SwinTransformerBlock(dim=embed_dim,\n",
        "                                             num_patch=num_patch,\n",
        "                                             num_heads=num_heads,\n",
        "                                             window_size=window_size,\n",
        "                                             shift_size=shift_size_temp,\n",
        "                                             num_mlp=num_mlp,\n",
        "                                             qkv_bias=qkv_bias,\n",
        "                                             qk_scale=qk_scale,\n",
        "                                             mlp_drop=mlp_drop_rate,\n",
        "                                             attn_drop=attn_drop_rate,\n",
        "                                             proj_drop=proj_drop_rate,\n",
        "                                             drop_path_prob=drop_path_rate,\n",
        "                                             name='name{}'.format(i))(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "def swin_unet_2d_base(input_tensor, filter_num_begin, depth, stack_num_down, stack_num_up,\n",
        "                      patch_size, num_heads, window_size, num_mlp, shift_window=True, name='swin_unet'):\n",
        "    '''\n",
        "    The base of Swin-UNET.\n",
        "\n",
        "    The general structure:\n",
        "\n",
        "    1. Input image --> a sequence of patches --> tokenize these patches\n",
        "    2. Downsampling: swin-transformer --> patch merging (pooling)\n",
        "    3. Upsampling: concatenate --> swin-transfprmer --> patch expanding (unpooling)\n",
        "    4. Model head\n",
        "\n",
        "    '''\n",
        "    # Compute number be patches to be embeded\n",
        "    input_size = input_tensor.shape.as_list()[1:]\n",
        "    num_patch_x = input_size[0]//patch_size[0]\n",
        "    num_patch_y = input_size[1]//patch_size[1]\n",
        "\n",
        "    # Number of Embedded dimensions\n",
        "    embed_dim = filter_num_begin\n",
        "\n",
        "    depth_ = depth\n",
        "\n",
        "    X_skip = []\n",
        "\n",
        "    X = input_tensor\n",
        "\n",
        "    # Patch extraction\n",
        "    X = transformer_layers.patch_extract(patch_size)(X)\n",
        "\n",
        "    # Embed patches to tokens\n",
        "    X = transformer_layers.patch_embedding(num_patch_x*num_patch_y, embed_dim)(X)\n",
        "\n",
        "    # The first Swin Transformer stack\n",
        "    X = swin_transformer_stack(X,\n",
        "                               stack_num=stack_num_down,\n",
        "                               embed_dim=embed_dim,\n",
        "                               num_patch=(num_patch_x, num_patch_y),\n",
        "                               num_heads=num_heads[0],\n",
        "                               window_size=window_size[0],\n",
        "                               num_mlp=num_mlp,\n",
        "                               shift_window=shift_window,\n",
        "                               name='{}_swin_down0'.format(name))\n",
        "    X_skip.append(X)\n",
        "\n",
        "    # Downsampling blocks\n",
        "    for i in range(depth_-1):\n",
        "\n",
        "        # Patch merging\n",
        "        X = transformer_layers.patch_merging((num_patch_x, num_patch_y), embed_dim=embed_dim, name='down{}'.format(i))(X)\n",
        "\n",
        "        # update token shape info\n",
        "        embed_dim = embed_dim*2\n",
        "        num_patch_x = num_patch_x//2\n",
        "        num_patch_y = num_patch_y//2\n",
        "\n",
        "        # Swin Transformer stacks\n",
        "        X = swin_transformer_stack(X,\n",
        "                                   stack_num=stack_num_down,\n",
        "                                   embed_dim=embed_dim,\n",
        "                                   num_patch=(num_patch_x, num_patch_y),\n",
        "                                   num_heads=num_heads[i+1],\n",
        "                                   window_size=window_size[i+1],\n",
        "                                   num_mlp=num_mlp,\n",
        "                                   shift_window=shift_window,\n",
        "                                   name='{}_swin_down{}'.format(name, i+1))\n",
        "\n",
        "        # Store tensors for concat\n",
        "        X_skip.append(X)\n",
        "\n",
        "    # reverse indexing encoded tensors and hyperparams\n",
        "    X_skip = X_skip[::-1]\n",
        "    num_heads = num_heads[::-1]\n",
        "    window_size = window_size[::-1]\n",
        "\n",
        "    # upsampling begins at the deepest available tensor\n",
        "    X = X_skip[0]\n",
        "\n",
        "    # other tensors are preserved for concatenation\n",
        "    X_decode = X_skip[1:]\n",
        "\n",
        "    depth_decode = len(X_decode)\n",
        "\n",
        "    for i in range(depth_decode):\n",
        "\n",
        "        # Patch expanding\n",
        "        X = transformer_layers.patch_expanding(num_patch=(num_patch_x, num_patch_y),\n",
        "                                               embed_dim=embed_dim,\n",
        "                                               upsample_rate=2,\n",
        "                                               return_vector=True)(X)\n",
        "\n",
        "\n",
        "        # update token shape info\n",
        "        embed_dim = embed_dim//2\n",
        "        num_patch_x = num_patch_x*2\n",
        "        num_patch_y = num_patch_y*2\n",
        "\n",
        "        # Concatenation and linear projection\n",
        "        X = concatenate([X, X_decode[i]], axis=-1, name='{}_concat_{}'.format(name, i))\n",
        "        X = Dense(embed_dim, use_bias=False, name='{}_concat_linear_proj_{}'.format(name, i))(X)\n",
        "\n",
        "        # Swin Transformer stacks\n",
        "        X = swin_transformer_stack(X,\n",
        "                                   stack_num=stack_num_up,\n",
        "                                   embed_dim=embed_dim,\n",
        "                                   num_patch=(num_patch_x, num_patch_y),\n",
        "                                   num_heads=num_heads[i],\n",
        "                                   window_size=window_size[i],\n",
        "                                   num_mlp=num_mlp,\n",
        "                                   shift_window=shift_window,\n",
        "                                   name='{}_swin_up{}'.format(name, i))\n",
        "\n",
        "    # The last expanding layer; it produces full-size feature maps based on the patch size\n",
        "    # !!! <--- \"patch_size[0]\" is used; it assumes patch_size = (size, size)\n",
        "\n",
        "    X = transformer_layers.patch_expanding(num_patch=(num_patch_x, num_patch_y),\n",
        "                                           embed_dim=embed_dim,\n",
        "                                           upsample_rate=patch_size[0],\n",
        "                                           return_vector=False)(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOOkt0xz_O7"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Hyperparameters of the Swin-UNET are listed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GU70_XFz_O-"
      },
      "outputs": [],
      "source": [
        "filter_num_begin = 192   # number of channels in the first downsampling block; it is also the number of embedded dimensions\n",
        "depth = 4                  # the depth of SwinUNET; depth=4 means three down/upsampling levels and a bottom level\n",
        "stack_num_down = 2         # number of Swin Transformers per downsampling level\n",
        "stack_num_up = 2           # number of Swin Transformers per upsampling level\n",
        "patch_size = (2,2)        # Extract 4-by-4 patches from the input image. Height and width of the patch must be equal.\n",
        "num_heads = [3, 6, 12, 24]   # number of attention heads per down/upsampling level\n",
        "window_size = [7, 7, 7, 7] # the size of attention window per down/upsampling level\n",
        "num_mlp = 6144              # number of MLP nodes within the Transformer\n",
        "shift_window=True          # Apply window shifting, i.e., Swin-MSA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fn1iyDGz_O_"
      },
      "source": [
        "## Model configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1Ot1-Ghz_PA"
      },
      "outputs": [],
      "source": [
        "#Input section\n",
        "input_size = (224, 224, 3)\n",
        "IN = Input(input_size)\n",
        "\n",
        "# Base architecture\n",
        "X = swin_unet_2d_base(IN, filter_num_begin, depth, stack_num_down, stack_num_up,\n",
        "                      patch_size, num_heads, window_size, num_mlp,\n",
        "                      shift_window=shift_window, name='swin_unet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08QbMp6yz_PC"
      },
      "outputs": [],
      "source": [
        "# Output section\n",
        "n_labels = 3\n",
        "OUT = Conv2D(n_labels, kernel_size=1, use_bias=False, activation='softmax')(X)\n",
        "\n",
        "# Model configuration\n",
        "model = Model(inputs=[IN,], outputs=[OUT,])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POqU4uhWz_PD"
      },
      "outputs": [],
      "source": [
        "# Optimization\n",
        "# <---- !!! gradient clipping is important\n",
        "opt = keras.optimizers.Adam(learning_rate=1e-4, clipvalue=0.5)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHiNJNLpz_PG"
      },
      "outputs": [],
      "source": [
        "def input_data_process(input_array):\n",
        "    '''converting pixel vales to [0, 1]'''\n",
        "    return input_array/255.\n",
        "\n",
        "def target_data_process(target_array):\n",
        "    '''Converting tri-mask of {1, 2, 3} to three categories.'''\n",
        "    # if target_array.all() >=  255 :\n",
        "    #    target_array = np.dot(target_array[...,0:3],[0.299, 0.587, 0.114])\n",
        "    #    return keras.utils.to_categorical(target_array-1)\n",
        "    # else :\n",
        "    # return target_array\n",
        "    return keras.utils.to_categorical((target_array))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_names = np.array(sorted(glob('/content/image_campur/*.jpg')))\n",
        "label_names = np.array(sorted(glob('/content/mask_campur/*.png')))\n",
        "\n",
        "L = len(sample_names)\n",
        "np.random.seed(212)\n",
        "ind_all = utils.shuffle_ind(L)\n",
        "\n",
        "L_train = int(0.8*L); L_valid = int(0.1*L); L_test = L - L_train - L_valid\n",
        "ind_train = ind_all[:L_train]; ind_valid = ind_all[L_train:L_train+L_valid]; ind_test = ind_all[L_train+L_valid:]\n",
        "print(\"Training:validation:testing = {}:{}:{}\".format(L_train, L_valid, L_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zy9u-ayWu0J",
        "outputId": "53d5861a-f877-4870-bee5-bc5f8a588661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:validation:testing = 960:120:120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oaJ8JRfz_PK"
      },
      "outputs": [],
      "source": [
        "valid_input = input_data_process(utils.image_to_array(sample_names[ind_valid], size=224, channel=3))\n",
        "valid_target = target_data_process(utils.image_to_array(label_names[ind_valid], size=224, channel=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(valid_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ8gb8mSsu3U",
        "outputId": "3357ba20-7057-4b41-becb-0b90b7a1244f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbv4BXicz_PL"
      },
      "outputs": [],
      "source": [
        "test_input = input_data_process(utils.image_to_array(sample_names[ind_test], size=224, channel=3))\n",
        "test_target = target_data_process(utils.image_to_array(label_names[ind_test], size=224, channel=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "w0Ca6XlOJBcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(sa[1], interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "HiayOCz2JB_h",
        "outputId": "9b5c18f3-9390-4c42-b682-d280c89de211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fwzVBRLtPbf",
        "outputId": "d52fe174-9192-4982-aee6-4b6b9e7a410a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "test_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDk1YzGotRH6",
        "outputId": "06a669dc-3915-4e85-befd-d29c28dfde24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "test_target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZgaF0iStD9E",
        "outputId": "af52a77f-de74-49b5-d4ee-3b9114a4aef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "valid_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZVtOrXTtJG5",
        "outputId": "5de0778c-e214-494c-e1dc-87ab92cb574a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "valid_target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bjCghRIz_PO"
      },
      "outputs": [],
      "source": [
        "N_epoch = 200 # number of epoches\n",
        "N_batch = 32 # number of batches per epoch\n",
        "N_sample = 16 # number of samples per batch\n",
        "\n",
        "tol = 0 # current early stopping patience\n",
        "max_tol = 10 # the max-allowed early stopping patience\n",
        "min_del = 0 # the lowest acceptable loss value reduction\n",
        "\n",
        "# loop over epoches\n",
        "for epoch in range(N_epoch):\n",
        "\n",
        "    # initial loss record\n",
        "    if epoch == 0:\n",
        "        y_pred = model.predict([valid_input])\n",
        "        record = np.mean(keras.losses.categorical_crossentropy(valid_target, y_pred))\n",
        "        print('\\tInitial loss = {}'.format(record))\n",
        "\n",
        "    # loop over batches\n",
        "    for step in range(N_batch):\n",
        "        # selecting smaples for the current batch\n",
        "        ind_train_shuffle = utils.shuffle_ind(L_train)[:N_sample]\n",
        "\n",
        "        # batch data formation\n",
        "        ## augmentation is not applied\n",
        "        train_input = input_data_process(\n",
        "            utils.image_to_array(sample_names[ind_train][ind_train_shuffle], size=224, channel=3))\n",
        "        train_target = target_data_process(\n",
        "            utils.image_to_array(label_names[ind_train][ind_train_shuffle], size=224, channel=1))\n",
        "\n",
        "        # train on batch\n",
        "        loss_ = model.train_on_batch([train_input,], [train_target,])\n",
        "#         if np.isnan(loss_):\n",
        "#             print(\"Training blow-up\")\n",
        "\n",
        "        # ** training loss is not stored ** #\n",
        "\n",
        "    # epoch-end validation\n",
        "    y_pred = model.predict([valid_input])\n",
        "    record_temp = np.mean(keras.losses.categorical_crossentropy(valid_target, y_pred))\n",
        "    # ** validation loss is not stored ** #\n",
        "\n",
        "    # if loss is reduced\n",
        "    if record - record_temp > min_del:\n",
        "        print('Validation performance is improved from {} to {}'.format(record, record_temp))\n",
        "        record = record_temp; # update the loss record\n",
        "        tol = 0; # refresh early stopping patience\n",
        "        # ** model checkpoint is not stored ** #\n",
        "\n",
        "    # if loss not reduced\n",
        "    else:\n",
        "        print('Validation performance {} is NOT improved'.format(record_temp))\n",
        "        tol += 1\n",
        "        if tol >= max_tol:\n",
        "            print('Early stopping')\n",
        "            break;\n",
        "        else:\n",
        "            # Pass to the next epoch\n",
        "            continue;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def metrics_np(y_true, y_pred, metric_name, metric_type='standard', drop_last = True, mean_per_class=False, verbose=False):\n",
        "    \"\"\"\n",
        "    Compute mean metrics of two segmentation masks, via numpy.\n",
        "\n",
        "    IoU(A,B) = |A & B| / (| A U B|)\n",
        "    Dice(A,B) = 2*|A & B| / (|A| + |B|)\n",
        "\n",
        "    Args:\n",
        "        y_true: true masks, one-hot encoded.\n",
        "        y_pred: predicted masks, either softmax outputs, or one-hot encoded.\n",
        "        metric_name: metric to be computed, either 'iou' or 'dice'.\n",
        "        metric_type: one of 'standard' (default), 'soft', 'naive'.\n",
        "          In the standard version, y_pred is one-hot encoded and the mean\n",
        "          is taken only over classes that are present (in y_true or y_pred).\n",
        "          The 'soft' version of the metrics are computed without one-hot\n",
        "          encoding y_pred.\n",
        "          The 'naive' version return mean metrics where absent classes contribute\n",
        "          to the class mean as 1.0 (instead of being dropped from the mean).\n",
        "        drop_last = True: boolean flag to drop last class (usually reserved\n",
        "          for background class in semantic segmentation)\n",
        "        mean_per_class = False: return mean along batch axis for each class.\n",
        "        verbose = False: print intermediate results such as intersection, union\n",
        "          (as number of pixels).\n",
        "    Returns:\n",
        "        IoU/Dice of y_true and y_pred, as a float, unless mean_per_class == True\n",
        "          in which case it returns the per-class metric, averaged over the batch.\n",
        "\n",
        "    Inputs are B*W*H*N tensors, with\n",
        "        B = batch size,\n",
        "        W = width,\n",
        "        H = height,\n",
        "        N = number of classes\n",
        "    \"\"\"\n",
        "\n",
        "    assert y_true.shape == y_pred.shape, 'Input masks should be same shape, instead are {}, {}'.format(y_true.shape, y_pred.shape)\n",
        "    assert len(y_pred.shape) == 4, 'Inputs should be B*W*H*N tensors, instead have shape {}'.format(y_pred.shape)\n",
        "\n",
        "    flag_soft = (metric_type == 'soft')\n",
        "    flag_naive_mean = (metric_type == 'naive')\n",
        "\n",
        "    num_classes = y_pred.shape[-1]\n",
        "    # if only 1 class, there is no background class and it should never be dropped\n",
        "    drop_last = drop_last and num_classes>1\n",
        "\n",
        "    if not flag_soft:\n",
        "        if num_classes>1:\n",
        "            # get one-hot encoded masks from y_pred (true masks should already be in correct format, do it anyway)\n",
        "            y_pred = np.array([ np.argmax(y_pred, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
        "            y_true = np.array([ np.argmax(y_true, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
        "        else:\n",
        "            y_pred = (y_pred > 0).astype(int)\n",
        "            y_true = (y_true > 0).astype(int)\n",
        "\n",
        "    # intersection and union shapes are batch_size * n_classes (values = area in pixels)\n",
        "    axes = (1,2) # W,H axes of each image\n",
        "    intersection = np.sum(np.abs(y_pred * y_true), axis=axes) # or, np.logical_and(y_pred, y_true) for one-hot\n",
        "    mask_sum = np.sum(np.abs(y_true), axis=axes) + np.sum(np.abs(y_pred), axis=axes)\n",
        "    union = mask_sum  - intersection # or, np.logical_or(y_pred, y_true) for one-hot\n",
        "\n",
        "    if verbose:\n",
        "        print('intersection (pred*true), intersection (pred&true), union (pred+true-inters), union (pred|true)')\n",
        "        print(intersection, np.sum(np.logical_and(y_pred, y_true), axis=axes), union, np.sum(np.logical_or(y_pred, y_true), axis=axes))\n",
        "\n",
        "    smooth = .001\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    dice = 2*(intersection + smooth)/(mask_sum + smooth)\n",
        "\n",
        "    metric = {'iou': iou, 'dice': dice}[metric_name]\n",
        "\n",
        "    # define mask to be 0 when no pixels are present in either y_true or y_pred, 1 otherwise\n",
        "    mask =  np.not_equal(union, 0).astype(int)\n",
        "    # mask = 1 - np.equal(union, 0).astype(int) # True = 1\n",
        "\n",
        "    if drop_last:\n",
        "        metric = metric[:,:-1]\n",
        "        mask = mask[:,:-1]\n",
        "\n",
        "    # return mean metrics: remaining axes are (batch, classes)\n",
        "    # if mean_per_class, average over batch axis only\n",
        "    # if flag_naive_mean, average over absent classes too\n",
        "    if mean_per_class:\n",
        "        if flag_naive_mean:\n",
        "            return np.mean(metric, axis=0)\n",
        "        else:\n",
        "            # mean only over non-absent classes in batch (still return 1 if class absent for whole batch)\n",
        "            return (np.sum(metric * mask, axis=0) + smooth)/(np.sum(mask, axis=0) + smooth)\n",
        "    else:\n",
        "        if flag_naive_mean:\n",
        "            return np.mean(metric)\n",
        "        else:\n",
        "            # mean only over non-absent classes\n",
        "            class_count = np.sum(mask, axis=0)\n",
        "            return np.mean(np.sum(metric * mask, axis=0)[class_count!=0]/(class_count[class_count!=0]))"
      ],
      "metadata": {
        "id": "5zybyQiH6iC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFDHlJuJuNrq"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2M7WsFiz_PP"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "The testing set performance is evaluated."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print('{:<60s} {:.3f}'.format('IoU of first class:', metrics_np(test_target[:,:,:,:1], y_pred[:,:,:,:1], metric_name='iou')))\n",
        "# print('{:<60s} {:.3f}'.format('IoU of second class:', metrics_np(test_target[:,:,:,1:2], y_pred[:,:,:,1:2], metric_name='iou')))\n",
        "# print('{:<60s} {:.3f}'.format('IoU of background:', metrics_np(test_target[:,:,:,-1:], y_pred[:,:,:,-1:], metric_name='iou')))\n",
        "print('{:<60s} {}'.format('IoU of each class (explicit list):', metrics_np(valid_target, y_pred, metric_name='iou', metric_type='naive', drop_last=False, mean_per_class=True)))\n",
        "# print('{:<60s} {:.3f}'.format('mean IoU of all classes (no background, naive mean):', metrics_np(test_target, y_pred, metric_name='iou', metric_type='naive')))\n",
        "# print('{:<60s} {:.3f}'.format('mean IoU of all classes (with background, naive mean):', metrics_np(test_target, y_pred, metric_name='iou', metric_type='naive', drop_last = False)))\n",
        "# print('{:<60s} {:.3f}'.format('mean IoU of all non-absent classes (dropping background):', metrics_np(test_target,ssssssssssssssssssssssssssssssss y_pred, metric_name='iou')))\n"
      ],
      "metadata": {
        "id": "UHwREGrSLyUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('{:<60s} {:.3f}'.format('IoU of first class:', metrics_np(test_target[:,:,:,:1], y_pred[:,:,:,:1], metric_name='iou')))\n",
        "# print('{:<60s} {:.3f}'.format('IoU of second class:', metrics_np(test_target[:,:,:,1:2], y_pred[:,:,:,1:2], metric_name='iou')))\n",
        "# print('{:<60s} {:.3f}'.format('IoU of background:', metrics_np(test_target[:,:,:,-1:], y_pred[:,:,:,-1:], metric_name='iou')))\n",
        "print('{:<60s} {}'.format('IoU of each class (explicit list):', metrics_np(test_target, y_pred, metric_name='iou', metric_type='naive', drop_last=False, mean_per_class=True)))\n",
        "# print('{:<60s} {:.3f}'.format('mean IoU of all classes (no background, naive mean):', metrics_np(test_target, y_pred, metric_name='iou', metric_type='naive')))\n",
        "# print('{:<60s} {:.3f}'.format('mean IoU of all classes (with background, naive mean):', metrics_np(test_target, y_pred, metric_name='iou', metric_type='naive', drop_last = False)))\n",
        "# print('{:<60s} {:.3f}'.format('mean IoU of all non-absent classes (dropping background):', metrics_np(test_target, y_pred, metric_name='iou')))\n"
      ],
      "metadata": {
        "id": "UDiiR5fqyfII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iou Salah satu"
      ],
      "metadata": {
        "id": "rWwGnR7HyP_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_true = test_target[130]\n",
        "y_pred = y_pred[130]  # they must be the same shape"
      ],
      "metadata": {
        "id": "RBQaUHRPzaVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_target"
      ],
      "metadata": {
        "id": "DPNlm3SD2ARh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_true.reshape((1,)+y_true.shape)"
      ],
      "metadata": {
        "id": "xl1Dh0Jj1bZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.reshape((1,)+y_pred.shape)"
      ],
      "metadata": {
        "id": "Uo_HT-EK1vIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true.shape"
      ],
      "metadata": {
        "id": "jQhnhHUe1m2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('{:<60s} {}'.format('IoU of each class (explicit list):', metrics_np(y_true, y_pred, metric_name='iou', metric_type='naive', drop_last=False, mean_per_class=True)))"
      ],
      "metadata": {
        "id": "z142kCeH0_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlNh1gd_Ss86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjatU_rrz_PQ"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict([test_input,])\n",
        "print('Testing set cross-entropy loss = {}'.format(np.mean(keras.losses.categorical_crossentropy(test_target, y_pred))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHwZHyRHak4d"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eInn7g7Nz_PR"
      },
      "source": [
        "**Example of outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jftOtr1fz_PR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm7XnMXYz_PS"
      },
      "outputs": [],
      "source": [
        "def ax_decorate_box(ax):\n",
        "    [j.set_linewidth(0) for j in ax.spines.values()]\n",
        "    ax.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False,\n",
        "                   labelbottom=False, left=False, right=False, labelleft=False)\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2q_tZsEz_PT"
      },
      "outputs": [],
      "source": [
        "i_sample = 2\n",
        "\n",
        "fig, AX = plt.subplots(1, 4, figsize=(13, (13-0.2)/4))\n",
        "plt.subplots_adjust(0, 0, 1, 1, hspace=0, wspace=0.1)\n",
        "for ax in AX:\n",
        "    ax = ax_decorate_box(ax)\n",
        "AX[0].pcolormesh(np.mean(test_input[i_sample, ...,], axis=-1), cmap=plt.cm.gray)\n",
        "AX[1].pcolormesh(y_pred[i_sample, ..., 0], cmap=plt.cm.jet)\n",
        "AX[2].pcolormesh(y_pred[i_sample, ..., 1], cmap=plt.cm.jet)\n",
        "# AX[3].pcolormesh(y_pred[i_sample, ..., 2], cmap=plt.cm.jet)\n",
        "\n",
        "AX[0].set_title(\"Original\", fontsize=14);\n",
        "AX[1].set_title(\"Pixels belong to the object\", fontsize=14);\n",
        "AX[2].set_title(\"Surrounding pixels\", fontsize=14);\n",
        "# AX[3].set_title(\"Bordering pixels\", fontsize=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bpn2jVeuz_PU"
      },
      "outputs": [],
      "source": [
        "    i_sample = 1\n",
        "    plt.subplot(1, 1, 1)\n",
        "    plt.imshow(y_pred[i_sample, ..., 0] )\n",
        "    plt.imshow(y_pred[i_sample, ..., 1] )\n",
        "    # plt.imshow(y_pred[i_sample, ..., 2] )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSiVvPCIfcby"
      },
      "outputs": [],
      "source": [
        "    i_sample = 1\n",
        "    plt.subplot(1, 1, 1)\n",
        "    plt.imshow(test_input[i_sample, ..., 0] )\n",
        "    plt.imshow(test_input[i_sample, ..., 1] )\n",
        "    plt.imshow(test_input[i_sample, ..., 2] )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knZ1XBYvf1hr"
      },
      "outputs": [],
      "source": [
        "    i_sample = 1\n",
        "    plt.subplot(1, 1, 1)\n",
        "    plt.imshow(test_target[i_sample, ..., 0] )\n",
        "    plt.imshow(test_target[i_sample, ..., 1] )\n",
        "    # plt.imshow(test_target[i_sample, ..., 2] )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.random.randint(0, high=120, size= 4, dtype=int)\n",
        "a=1\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(20, 20), dpi=80)\n",
        "\n",
        "for i in range (len(x)):\n",
        "    plt.subplot(4,3,a)\n",
        "    plt.title('Orignal Mask')\n",
        "    plt.imshow(np.argmax(test_target[x[i]],axis=2)*255)\n",
        "    plt.subplot(4,3,a+1)\n",
        "    plt.imshow(np.argmax(y_pred[x[i]],axis=2)*255)\n",
        "    plt.title('Predicted Mask')\n",
        "    Error=np.argmax(y_pred[x[i]],axis=2)*255-np.argmax(test_target[x[i]],axis=2)*255\n",
        "    plt.subplot(4,3,a+2)\n",
        "    plt.imshow(Error)\n",
        "    plt.title('Error ')\n",
        "    a=a+3\n",
        "#plt.figure(figsize = (10,10))\n",
        "plt.savefig('Results.png',transparent=True)"
      ],
      "metadata": {
        "id": "FQsMivRH5yoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def metrics_np(y_true, y_pred, metric_name, metric_type='standard', drop_last = True, mean_per_class=False, verbose=False):\n",
        "    \"\"\"\n",
        "    Compute mean metrics of two segmentation masks, via numpy.\n",
        "\n",
        "    IoU(A,B) = |A & B| / (| A U B|)\n",
        "    Dice(A,B) = 2*|A & B| / (|A| + |B|)\n",
        "\n",
        "    Args:\n",
        "        y_true: true masks, one-hot encoded.\n",
        "        y_pred: predicted masks, either softmax outputs, or one-hot encoded.\n",
        "        metric_name: metric to be computed, either 'iou' or 'dice'.\n",
        "        metric_type: one of 'standard' (default), 'soft', 'naive'.\n",
        "          In the standard version, y_pred is one-hot encoded and the mean\n",
        "          is taken only over classes that are present (in y_true or y_pred).\n",
        "          The 'soft' version of the metrics are computed without one-hot\n",
        "          encoding y_pred.\n",
        "          The 'naive' version return mean metrics where absent classes contribute\n",
        "          to the class mean as 1.0 (instead of being dropped from the mean).\n",
        "        drop_last = True: boolean flag to drop last class (usually reserved\n",
        "          for background class in semantic segmentation)\n",
        "        mean_per_class = False: return mean along batch axis for each class.\n",
        "        verbose = False: print intermediate results such as intersection, union\n",
        "          (as number of pixels).\n",
        "    Returns:\n",
        "        IoU/Dice of y_true and y_pred, as a float, unless mean_per_class == True\n",
        "          in which case it returns the per-class metric, averaged over the batch.\n",
        "\n",
        "    Inputs are B*W*H*N tensors, with\n",
        "        B = batch size,\n",
        "        W = width,\n",
        "        H = height,\n",
        "        N = number of classes\n",
        "    \"\"\"\n",
        "\n",
        "    assert y_true.shape == y_pred.shape, 'Input masks should be same shape, instead are {}, {}'.format(y_true.shape, y_pred.shape)\n",
        "    assert len(y_pred.shape) == 4, 'Inputs should be B*W*H*N tensors, instead have shape {}'.format(y_pred.shape)\n",
        "\n",
        "    flag_soft = (metric_type == 'soft')\n",
        "    flag_naive_mean = (metric_type == 'naive')\n",
        "\n",
        "    num_classes = y_pred.shape[-1]\n",
        "    # if only 1 class, there is no background class and it should never be dropped\n",
        "    drop_last = drop_last and num_classes>1\n",
        "\n",
        "    if not flag_soft:\n",
        "        if num_classes>1:\n",
        "            # get one-hot encoded masks from y_pred (true masks should already be in correct format, do it anyway)\n",
        "            y_pred = np.array([ np.argmax(y_pred, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
        "            y_true = np.array([ np.argmax(y_true, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
        "        else:\n",
        "            y_pred = (y_pred > 0).astype(int)\n",
        "            y_true = (y_true > 0).astype(int)\n",
        "\n",
        "    # intersection and union shapes are batch_size * n_classes (values = area in pixels)\n",
        "    axes = (1,2) # W,H axes of each image\n",
        "    intersection = np.sum(np.abs(y_pred * y_true), axis=axes) # or, np.logical_and(y_pred, y_true) for one-hot\n",
        "    mask_sum = np.sum(np.abs(y_true), axis=axes) + np.sum(np.abs(y_pred), axis=axes)\n",
        "    union = mask_sum  - intersection # or, np.logical_or(y_pred, y_true) for one-hot\n",
        "\n",
        "    if verbose:\n",
        "        print('intersection (pred*true), intersection (pred&true), union (pred+true-inters), union (pred|true)')\n",
        "        print(intersection, np.sum(np.logical_and(y_pred, y_true), axis=axes), union, np.sum(np.logical_or(y_pred, y_true), axis=axes))\n",
        "\n",
        "    smooth = .001\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    dice = 2*(intersection + smooth)/(mask_sum + smooth)\n",
        "\n",
        "    metric = {'iou': iou, 'dice': dice}[metric_name]\n",
        "\n",
        "    # define mask to be 0 when no pixels are present in either y_true or y_pred, 1 otherwise\n",
        "    mask =  np.not_equal(union, 0).astype(int)\n",
        "    # mask = 1 - np.equal(union, 0).astype(int) # True = 1\n",
        "\n",
        "    if drop_last:\n",
        "        metric = metric[:,:-1]\n",
        "        mask = mask[:,:-1]\n",
        "\n",
        "    # return mean metrics: remaining axes are (batch, classes)\n",
        "    # if mean_per_class, average over batch axis only\n",
        "    # if flag_naive_mean, average over absent classes too\n",
        "    if mean_per_class:\n",
        "        if flag_naive_mean:\n",
        "            return np.mean(metric, axis=0)\n",
        "        else:\n",
        "            # mean only over non-absent classes in batch (still return 1 if class absent for whole batch)\n",
        "            return (np.sum(metric * mask, axis=0) + smooth)/(np.sum(mask, axis=0) + smooth)\n",
        "    else:\n",
        "        if flag_naive_mean:\n",
        "            return np.mean(metric)\n",
        "        else:\n",
        "            # mean only over non-absent classes\n",
        "            class_count = np.sum(mask, axis=0)\n",
        "            return np.mean(np.sum(metric * mask, axis=0)[class_count!=0]/(class_count[class_count!=0]))"
      ],
      "metadata": {
        "id": "yHUFx07R1ots"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image\n",
        "\n",
        "matplotlib.image.imsave('name.png', y_pred[0])"
      ],
      "metadata": {
        "id": "IibqEk8S-tUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA FRAME"
      ],
      "metadata": {
        "id": "zgy-oF784-rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zJ0JytCC4V-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_excel('Glaucoma_label_Test.xlsx')"
      ],
      "metadata": {
        "id": "Rzeo8syK5Cb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid = pd.read_excel('Glaucoma_label_Valid.xlsx')"
      ],
      "metadata": {
        "id": "WTQ_yW4z5C8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_excel('Glaucoma_label_tain.xlsx')"
      ],
      "metadata": {
        "id": "oKPCTEVg5DPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CEK"
      ],
      "metadata": {
        "id": "XitwEKnY5rWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "2cu7JZ2t5joE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid.head()"
      ],
      "metadata": {
        "id": "6SyMySay5og7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "6o-8IfjF5qUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penggabungan\n"
      ],
      "metadata": {
        "id": "ABkBR5ck7G8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frameList = [df_valid, df_test]"
      ],
      "metadata": {
        "id": "5whUPCD07IKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_com = pd.concat(frameList)"
      ],
      "metadata": {
        "id": "2xEV4Upd7Iyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frameList = [df_com, df_train]"
      ],
      "metadata": {
        "id": "9PA7cNw17Ofg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dom = pd.concat(frameList)"
      ],
      "metadata": {
        "id": "fJvbvgzy7RKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dom.drop([\"ID\", \"Fovea_X\", \"Fovea_Y\"], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "zMzVItQ57dkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kumpul = pd.concat(frameList)"
      ],
      "metadata": {
        "id": "ODJCg_kn8JVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kumpul"
      ],
      "metadata": {
        "id": "FtaiRuPv8Lwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mulai menyusun hasil\n"
      ],
      "metadata": {
        "id": "SBvlQEBc8_En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = sorted(glob('/content/Images_Cropped/*.jpg'))\n",
        "masks = sorted(glob('/content/Masks_Cropped/*.png'))"
      ],
      "metadata": {
        "id": "ndbU3FuR9GZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daftar_name = []"
      ],
      "metadata": {
        "id": "tAUKjlEi9Kfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in zip(images, masks) :\n",
        "  daftar = x.split('/')[-1]\n",
        "  daftar_name.append(daftar)\n",
        "print(daftar_name)"
      ],
      "metadata": {
        "id": "JpyJFGb49LET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(daftar_name)"
      ],
      "metadata": {
        "id": "qq6ZHuy09OTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dv = pd.DataFrame(daftar_name, columns =['Nama'])\n",
        "dv[\"ID\"] = dv.index\n",
        "dv = dv[['ID', 'Nama']]\n",
        "dv"
      ],
      "metadata": {
        "id": "Fhvunm979lf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dy = pd.DataFrame(ind_train, columns =['ID'])"
      ],
      "metadata": {
        "id": "PtOxwU_-9w5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dy['marker'] = 1\n",
        "dy"
      ],
      "metadata": {
        "id": "aK4bIW6X93M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined = pd.merge(dv, dy, on=['ID'], how='left')\n",
        "joined"
      ],
      "metadata": {
        "id": "0PAJoDim972X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained = joined[pd.notnull(joined['marker'])][dv.columns]\n",
        "trained['No'] = np.arange(len(trained))\n",
        "trained = trained[['No','ID', 'Nama']]"
      ],
      "metadata": {
        "id": "VjtXFJIT-Cgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained"
      ],
      "metadata": {
        "id": "I8nZowa5-GuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dx = pd.DataFrame(ind_valid, columns =['ID'])"
      ],
      "metadata": {
        "id": "JtlbtaBp-Nbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dx['marker'] = 1\n",
        "dx"
      ],
      "metadata": {
        "id": "JM8v8_j--S8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined = pd.merge(dv, dx, on=['ID'], how='left')\n",
        "joined"
      ],
      "metadata": {
        "id": "T2zk0N5--V6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valided = joined[pd.notnull(joined['marker'])][dv.columns]\n",
        "valided['No'] = np.arange(len(valided))\n",
        "valided = valided[['No','ID', 'Nama']]"
      ],
      "metadata": {
        "id": "WjmtlYKV-Yfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valided"
      ],
      "metadata": {
        "id": "5MjQ6AlX-f59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dj = pd.DataFrame(ind_test, columns =['ID'])\n"
      ],
      "metadata": {
        "id": "mArx1ghX-kLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dj['marker'] = 1\n",
        "dj"
      ],
      "metadata": {
        "id": "3Yubauzr-n4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined = pd.merge(dv, dj, on=['ID'], how='left')\n",
        "joined"
      ],
      "metadata": {
        "id": "_q3DHZli-rrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested = joined[pd.notnull(joined['marker'])][dv.columns]\n",
        "tested['No'] = np.arange(len(tested))\n",
        "tested = tested[['No','ID', 'Nama']]"
      ],
      "metadata": {
        "id": "XPeNUtKF-uCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested"
      ],
      "metadata": {
        "id": "Iis3s9iG-wKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ngitung CDR"
      ],
      "metadata": {
        "id": "ncxDM34B_I2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od = y_pred[:,:,:,1]"
      ],
      "metadata": {
        "id": "wYvPegkm-z9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oc = y_pred[:,:,:,2]"
      ],
      "metadata": {
        "id": "XAIpwZ6O-9Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vertical_diameter(binary_segmentation):\n",
        "    '''\n",
        "    Get the vertical diameter from a binary segmentation.\n",
        "    The vertical diameter is defined as the \"fattest\" area of the binary_segmentation parameter.\n",
        "    '''\n",
        "\n",
        "    # get the sum of the pixels in the vertical axis\n",
        "    vertical_axis_diameter = np.sum(binary_segmentation, axis=0)\n",
        "\n",
        "    # pick the maximum value\n",
        "    diameter = np.max(vertical_axis_diameter, axis=0)\n",
        "\n",
        "    # return it\n",
        "    return diameter"
      ],
      "metadata": {
        "id": "b-JB_mSEAuhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "satu = vertical_diameter(oc[1])\n",
        "\n",
        "print(satu)"
      ],
      "metadata": {
        "id": "K6L7Dc6mBEZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vertical_cup_to_disc_ratio(od, oc):\n",
        "    '''\n",
        "    Compute the vertical cup-to-disc ratio from a given labelling map.\n",
        "    '''\n",
        "    EPS = 1e-7\n",
        "    # compute the cup diameter\n",
        "    cup_diameter = vertical_diameter(oc)\n",
        "    # compute the disc diameter\n",
        "    disc_diameter = vertical_diameter(od)\n",
        "\n",
        "    return cup_diameter / (disc_diameter + EPS)"
      ],
      "metadata": {
        "id": "3HKSCWUBAwpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jumlah = []\n",
        "i = 0\n",
        "j = 0"
      ],
      "metadata": {
        "id": "nL-LO93HA1r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(oc)):\n",
        "    hasil = vertical_cup_to_disc_ratio(od[i],oc[j])\n",
        "    jumlah.append(hasil)\n",
        "    i = i + 1\n",
        "    j = j + 1"
      ],
      "metadata": {
        "id": "cK5rPshrA6LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(jumlah, columns=['Vcdr'])\n",
        "df"
      ],
      "metadata": {
        "id": "-OC514uZA80l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "tsh =  0.6\n",
        "# while tsh < 1:\n",
        "predicted = []\n",
        "for row in df['Vcdr']:\n",
        "  if row > tsh:\n",
        "    predicted.append(1)\n",
        "  else:\n",
        "    predicted.append(0)\n",
        "df['Vcdr_label'] =  predicted\n",
        "    # print(f\"treshold = {tsh:.2f}, accuracy  : {accuracy_score(df['label'], df['Vcdr_label']):.3f}\")"
      ],
      "metadata": {
        "id": "HPeyjGK0EZKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['No'] = np.arange(len(df))\n",
        "df = df[['No','Vcdr', 'Vcdr_label']]"
      ],
      "metadata": {
        "id": "jCYIJ9thEc85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "campur = pd.merge(tested, df, on=['No'], how='left')"
      ],
      "metadata": {
        "id": "yDv2yxK1EmGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "campur.head()"
      ],
      "metadata": {
        "id": "d9iueSM3Eues"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "campur.to_csv('Hasil_Vcdr.csv', index=False)"
      ],
      "metadata": {
        "id": "y7UZ-9GbE5g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ngambil data ground truth"
      ],
      "metadata": {
        "id": "S9Yq-bRZE-ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_kumpul.head()"
      ],
      "metadata": {
        "id": "HJrmlLdMFB8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested.head()"
      ],
      "metadata": {
        "id": "zJCaIN5MGrPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested.columns = tested.columns.str.replace('Nama', 'ImgName')"
      ],
      "metadata": {
        "id": "3bpjys56G5D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested.drop([\"No\", \"ID\"], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "B6MzpOT9H3T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested['marker'] = 1\n",
        "tested"
      ],
      "metadata": {
        "id": "Q-GePqBZHDJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined = pd.merge(df_kumpul, tested, on=['ImgName'], how='left')\n",
        "joined"
      ],
      "metadata": {
        "id": "q2Zbw6kRHMCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = joined[pd.notnull(joined['marker'])][df_kumpul]\n",
        "# trained['No'] = np.arange(len(trained))\n",
        "# trained = trained[['No','ID', 'Nama']]"
      ],
      "metadata": {
        "id": "ADvucHgiHbEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kumpul[~df_kumpul.apply(tuple,1).isin(tested.apply(tuple,1))]"
      ],
      "metadata": {
        "id": "vd6nh39IKbp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loha = df_kumpul.merge(tested,indicator = True, how='left').loc[lambda x : x['_merge']=='both']"
      ],
      "metadata": {
        "id": "oNp20d5zKmal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loha"
      ],
      "metadata": {
        "id": "tpe3qGDoL1LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loha.drop([\"marker\", \"_merge\"], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "X23SM9dLLqjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loha.to_csv('Hasil_GT.csv', index=False)"
      ],
      "metadata": {
        "id": "C6c9ygifMBgp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}